{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9340fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exyzt/projects/DSA4212-Transformer-Project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from flax.linen import attention as attn\n",
    "from typing import Any, Callable\n",
    "import optax\n",
    "import time\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd().parent\n",
    "sys.path.append(str(root))\n",
    "\n",
    "from models.decoder_only_transformer_RoPE import DecoderOnlyTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d006c",
   "metadata": {},
   "source": [
    "### Check GPU Availablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761e557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX is using: gpu\n",
      "All available devices: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "print(\"JAX is using:\", jax.default_backend())\n",
    "print(\"All available devices:\", jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc968a22",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f402b5b7",
   "metadata": {},
   "source": [
    "#### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66ddabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"afmck/text8\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0][\"text\"][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4190f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train text: 90,000,000 characters\n",
      "Length of validation text: 5,000,000 characters\n"
     ]
    }
   ],
   "source": [
    "train_text = dataset[\"train\"][0][\"text\"]\n",
    "val_text = dataset[\"validation\"][0][\"text\"]\n",
    "\n",
    "print(f\"Length of train text: {len(train_text):,} characters\")\n",
    "print(f\"Length of validation text: {len(val_text):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55e1cf",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde073cc",
   "metadata": {},
   "source": [
    "#### Building the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaba3c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test string 1: hello world\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary (lowercase + space + a few punctuations)\n",
    "char_set = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "char_to_int = {ch:i for i,ch in enumerate(char_set)}\n",
    "int_to_char = {i:ch for ch,i in char_to_int.items()}\n",
    "\n",
    "def encode(s):\n",
    "    \"\"\"Encode string to array of integers\"\"\"\n",
    "    ids = [char_to_int[c] for c in s]\n",
    "    return np.array(ids, dtype=np.uint8)  # use np.uint8 to save space\n",
    "\n",
    "def decode(ids):\n",
    "    \"\"\"Decode array of integers to string\"\"\"\n",
    "    return ''.join(int_to_char[i] for i in ids)\n",
    "# Test encoding and decoding\n",
    "test_str = \"hello world\"\n",
    "encoded = encode(test_str)\n",
    "decoded = decode(encoded)\n",
    "assert test_str == decoded, \"Encoding/decoding failed\"\n",
    "print(f\"Test string 1: {test_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e5c30",
   "metadata": {},
   "source": [
    "#### Tokenize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7579b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_int = encode(train_text)\n",
    "test_text_int = encode(val_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42813b07",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd563bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(\n",
    "    rng,\n",
    "    vocab_size,\n",
    "    d_model,\n",
    "    n_layers,\n",
    "    n_heads,\n",
    "    mlp_ratio,\n",
    "    emb_dropout,\n",
    "    attn_dropout,\n",
    "    mlp_dropout,\n",
    "    param_dtype,\n",
    "    compute_dtype,\n",
    "    kernel_init,\n",
    "    proj_init,\n",
    "):\n",
    "\n",
    "    # Instantiate the model with all given hyperparameters\n",
    "    model = DecoderOnlyTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=d_model,\n",
    "        n_layers=n_layers,\n",
    "        n_heads=n_heads,\n",
    "        mlp_ratio=mlp_ratio,\n",
    "        emb_dropout=emb_dropout,\n",
    "        attn_dropout=attn_dropout,\n",
    "        mlp_dropout=mlp_dropout,\n",
    "        param_dtype=param_dtype,\n",
    "        compute_dtype=compute_dtype,\n",
    "        kernel_init=kernel_init,\n",
    "        proj_init=proj_init,\n",
    "    )\n",
    "\n",
    "    # Create dummy input for initialization (single batch of zeros)\n",
    "    dummy = jnp.zeros((1, 16), dtype=jnp.int32)\n",
    "\n",
    "    # Initialize model parameters (include dropout rng)\n",
    "    variables = model.init({\"params\": rng, \"dropout\": rng}, dummy, deterministic=False)\n",
    "\n",
    "    # Extract parameters only (not batch stats etc.)\n",
    "    params = variables[\"params\"]\n",
    "\n",
    "    return model, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb675e8",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b028189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_and_metrics(logits, targets):\n",
    "    \"\"\"Compute cross-entropy loss and accuracy.\n",
    "\n",
    "    Assumes `targets` contains only valid integer class ids in [0, V-1] (no -1 ignore tokens).\n",
    "\n",
    "    Args:\n",
    "      logits: (B, T, V) float array of unnormalized scores.\n",
    "      targets: (B, T) integer array with ground-truth class ids.\n",
    "\n",
    "    Returns:\n",
    "      loss: scalar average cross-entropy over all positions.\n",
    "      metrics: dict with keys \"loss\" and \"acc\" (both scalars).\n",
    "    \"\"\"\n",
    "    # Flatten batch/time dims so optax works on shape (N, V) and (N,)\n",
    "    vocab = logits.shape[-1]\n",
    "    flat_logits = logits.reshape(-1, vocab)\n",
    "    flat_targets = targets.reshape(-1)\n",
    "\n",
    "    # Per-position cross-entropy, then mean over all positions\n",
    "    per_pos = optax.softmax_cross_entropy_with_integer_labels(flat_logits, flat_targets)\n",
    "    loss = per_pos.mean()\n",
    "\n",
    "    # prediction over all positions\n",
    "    preds = jnp.argmax(logits, axis=-1)  # (B, T)\n",
    "    \n",
    "    # compute accuracy over only the last position\n",
    "    is_match = preds == targets\n",
    "    \n",
    "    # Accuracy over all positions\n",
    "    acc_all = jnp.mean(is_match.astype(jnp.float32))\n",
    "    \n",
    "    # Accuracy over only last position\n",
    "    acc_last = jnp.mean(is_match.astype(jnp.float32)[:,-1])\n",
    "\n",
    "    return loss, {\"loss\": loss, \"acc\": acc_all, \"acc_last\": acc_last}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54395e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mexyzt3d\u001b[0m (\u001b[33mexyzt3d-nus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/exyzt/projects/DSA4212-Transformer-Project/Notebooks/wandb/run-20251119_001932-sp9q78ro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks/runs/sp9q78ro' target=\"_blank\">Decoder-Only-Transformers w/ RoPE - Test 3</a></strong> to <a href='https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks' target=\"_blank\">https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks/runs/sp9q78ro' target=\"_blank\">https://wandb.ai/exyzt3d-nus/DSA4212-Transformer-Project-Notebooks/runs/sp9q78ro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "configs = {\n",
    "    \"vocab_size\": len(char_set),\n",
    "    \"d_model\": 256,\n",
    "    \"n_layers\": 6,\n",
    "    \"n_heads\": 8,\n",
    "    \"mlp_ratio\": 4,\n",
    "    \"emb_dropout\": 0.1,\n",
    "    \"attn_dropout\": 0.1,\n",
    "    \"mlp_dropout\": 0.1,\n",
    "    \"param_dtype\": jnp.float32,\n",
    "    \"compute_dtype\": jnp.float32,\n",
    "    \"kernel_init\": nn.initializers.xavier_normal(),\n",
    "    \"proj_init\": nn.initializers.normal(stddev=1e-4),\n",
    "    \"learning_rate\": optax.warmup_exponential_decay_schedule(\n",
    "        init_value=0.0,\n",
    "        peak_value=6e-4,\n",
    "        warmup_steps=2000,\n",
    "        decay_steps=100000,\n",
    "    ),\n",
    "    \"optimizer\": optax.adamw,\n",
    "}\n",
    "\n",
    "model_params = [\n",
    "    \"vocab_size\",\n",
    "    \"d_model\",\n",
    "    \"n_layers\",\n",
    "    \"n_heads\",\n",
    "    \"mlp_ratio\",\n",
    "    \"emb_dropout\",\n",
    "    \"attn_dropout\",\n",
    "    \"mlp_dropout\",\n",
    "    \"param_dtype\",\n",
    "    \"compute_dtype\",\n",
    "    \"kernel_init\",\n",
    "    \"proj_init\",\n",
    "]\n",
    "\n",
    "model_configs = {param: configs[param] for param in model_params}\n",
    "\n",
    "model, params = create_train_state(rng, **model_configs)\n",
    "\n",
    "# Run logging with Wandb\n",
    "wandb.login()\n",
    "\n",
    "run = wandb.init(\n",
    "    config=configs,\n",
    "    name=\"Decoder-Only-Transformers w/ RoPE - Test 4\",\n",
    "    notes=\"Warmup Exponential Decay Schedule, Batch = 128, Context Length = 64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd9f74",
   "metadata": {},
   "source": [
    "### Optimization Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a035f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an update function\n",
    "def train_step(params, opt_state, x, y, tx):\n",
    "    \"\"\"Single optimization step using optax optimizer.\n",
    "\n",
    "    Args:\n",
    "      params: pytree of model parameters.\n",
    "      opt_state: optax optimizer state corresponding to `params`.\n",
    "      x: (B, T) int array input tokens.\n",
    "      y: (B, T) int array target tokens.\n",
    "      tx: optax.GradientTransformation (already initialized).\n",
    "\n",
    "    Returns:\n",
    "      new_params: updated parameters after one gradient step.\n",
    "      new_opt_state: updated optimizer state.\n",
    "      metrics: dict of scalar metrics (loss, acc).\n",
    "    \"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = model.apply({\"params\": params}, x)\n",
    "        loss, metrics = loss_and_metrics(logits, y)\n",
    "        return loss, metrics\n",
    "\n",
    "    # compute gradients (loss is scalar, metrics is auxiliary)\n",
    "    (loss, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "\n",
    "    # optax update: compute parameter updates and new optimizer state\n",
    "    updates, new_opt_state = tx.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state, metrics\n",
    "\n",
    "# jit: last argument should be static because it is an object\n",
    "train_step = jax.jit(train_step, static_argnames=(\"tx\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcdfa20",
   "metadata": {},
   "source": [
    "### Batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b73a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch from the training data\n",
    "def get_batch(text_int, B, T):\n",
    "    \"\"\"Create a random batch of data from text_int.\n",
    "\n",
    "    Args:\n",
    "      text_int: 1D array of token ids.\n",
    "      B: batch size (number of sequences).\n",
    "      T: sequence length (number of tokens per sequence).\n",
    "\n",
    "    Returns:\n",
    "      x: (B, T) int array input tokens.\n",
    "      y: (B, T) int array target tokens.\n",
    "    \"\"\"\n",
    "    # choose random starting indices for each sequence in the batch\n",
    "    ix = np.random.randint(0, len(text_int) - T, size=B)\n",
    "    # inputs are text from i to i+T\n",
    "    x = np.stack([text_int[i:i+T] for i in ix])\n",
    "    # targets are text from i+1 to i+T+1\n",
    "    y = np.stack([text_int[i+1:i+T+1] for i in ix])\n",
    "    return jnp.array(x, dtype=jnp.int32), jnp.array(y, dtype=jnp.int32)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a36ac",
   "metadata": {},
   "source": [
    "### Optimizer Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3324add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized optimizer: AdamW lr=<function join_schedules.<locals>.schedule at 0x7eb20a12dd00>\n"
     ]
    }
   ],
   "source": [
    "# define optax optimizer\n",
    "learning_rate = configs[\"learning_rate\"]\n",
    "# Create AdamW optimizer (Optax)\n",
    "tx = configs[\"optimizer\"](learning_rate=learning_rate)\n",
    "# Initialize optimizer state for current params\n",
    "opt_state = tx.init(params)\n",
    "print(f\"Initialized optimizer: AdamW lr={learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1  time: 15.3 seconds\n",
      "\t \t loss(train :: test): 3.2958 :: 3.2958\n",
      "\t \t accuracy (train :: test): 3.7% :: 4.1%\n",
      "\t \t accuracy (last character) (train :: test): 1.6% :: 4.4%\n",
      "\n",
      "iteration 2_000  time: 217.4 seconds\n",
      "\t \t loss(train :: test): 1.3480 :: 1.3719\n",
      "\t \t accuracy (train :: test): 57.9% :: 57.1%\n",
      "\t \t accuracy (last character) (train :: test): 64.1% :: 60.5%\n",
      "\n",
      "iteration 4_000  time: 413.7 seconds\n",
      "\t \t loss(train :: test): 1.2060 :: 1.2735\n",
      "\t \t accuracy (train :: test): 61.9% :: 60.2%\n",
      "\t \t accuracy (last character) (train :: test): 60.5% :: 62.2%\n",
      "\n",
      "iteration 6_000  time: 747.1 seconds\n",
      "\t \t loss(train :: test): 1.2082 :: 1.2425\n",
      "\t \t accuracy (train :: test): 62.1% :: 60.9%\n",
      "\t \t accuracy (last character) (train :: test): 63.7% :: 62.9%\n",
      "\n",
      "iteration 8_000  time: 1156.1 seconds\n",
      "\t \t loss(train :: test): 1.1908 :: 1.2422\n",
      "\t \t accuracy (train :: test): 62.4% :: 60.9%\n",
      "\t \t accuracy (last character) (train :: test): 64.5% :: 63.5%\n",
      "\n",
      "iteration 10_000  time: 1558.6 seconds\n",
      "\t \t loss(train :: test): 1.1570 :: 1.1784\n",
      "\t \t accuracy (train :: test): 63.4% :: 62.9%\n",
      "\t \t accuracy (last character) (train :: test): 62.9% :: 66.4%\n",
      "\n",
      "iteration 12_000  time: 1958.7 seconds\n",
      "\t \t loss(train :: test): 1.1233 :: 1.1915\n",
      "\t \t accuracy (train :: test): 64.4% :: 62.5%\n",
      "\t \t accuracy (last character) (train :: test): 66.4% :: 64.2%\n",
      "\n",
      "iteration 14_000  time: 2359.4 seconds\n",
      "\t \t loss(train :: test): 1.1465 :: 1.2107\n",
      "\t \t accuracy (train :: test): 64.0% :: 61.6%\n",
      "\t \t accuracy (last character) (train :: test): 64.5% :: 65.0%\n",
      "\n",
      "iteration 16_000  time: 2587.4 seconds\n",
      "\t \t loss(train :: test): 1.1283 :: 1.1933\n",
      "\t \t accuracy (train :: test): 64.5% :: 62.3%\n",
      "\t \t accuracy (last character) (train :: test): 64.1% :: 66.5%\n",
      "\n",
      "iteration 18_000  time: 2786.0 seconds\n",
      "\t \t loss(train :: test): 1.1142 :: 1.1851\n",
      "\t \t accuracy (train :: test): 65.0% :: 62.7%\n",
      "\t \t accuracy (last character) (train :: test): 71.9% :: 68.3%\n",
      "\n",
      "iteration 20_000  time: 2984.0 seconds\n",
      "\t \t loss(train :: test): 1.0952 :: 1.1686\n",
      "\t \t accuracy (train :: test): 65.5% :: 62.7%\n",
      "\t \t accuracy (last character) (train :: test): 66.4% :: 66.1%\n",
      "\n",
      "iteration 22_000  time: 3184.8 seconds\n",
      "\t \t loss(train :: test): 1.1259 :: 1.1662\n",
      "\t \t accuracy (train :: test): 64.4% :: 62.9%\n",
      "\t \t accuracy (last character) (train :: test): 67.2% :: 67.9%\n",
      "\n",
      "iteration 24_000  time: 3384.9 seconds\n",
      "\t \t loss(train :: test): 1.0911 :: 1.1613\n",
      "\t \t accuracy (train :: test): 65.4% :: 62.9%\n",
      "\t \t accuracy (last character) (train :: test): 67.2% :: 68.4%\n",
      "\n",
      "iteration 26_000  time: 3585.3 seconds\n",
      "\t \t loss(train :: test): 1.0943 :: 1.1619\n",
      "\t \t accuracy (train :: test): 65.6% :: 63.2%\n",
      "\t \t accuracy (last character) (train :: test): 65.2% :: 69.1%\n",
      "\n",
      "iteration 28_000  time: 3789.0 seconds\n",
      "\t \t loss(train :: test): 1.0877 :: 1.1512\n",
      "\t \t accuracy (train :: test): 65.5% :: 63.6%\n",
      "\t \t accuracy (last character) (train :: test): 73.0% :: 68.8%\n",
      "\n",
      "iteration 30_000  time: 3991.2 seconds\n",
      "\t \t loss(train :: test): 1.1002 :: 1.1664\n",
      "\t \t accuracy (train :: test): 65.2% :: 63.4%\n",
      "\t \t accuracy (last character) (train :: test): 66.8% :: 67.3%\n",
      "\n",
      "iteration 32_000  time: 4194.1 seconds\n",
      "\t \t loss(train :: test): 1.1158 :: 1.1501\n",
      "\t \t accuracy (train :: test): 64.9% :: 63.8%\n",
      "\t \t accuracy (last character) (train :: test): 67.2% :: 70.1%\n",
      "\n",
      "iteration 34_000  time: 4396.3 seconds\n",
      "\t \t loss(train :: test): 1.0595 :: 1.1672\n",
      "\t \t accuracy (train :: test): 66.7% :: 63.1%\n",
      "\t \t accuracy (last character) (train :: test): 68.0% :: 66.0%\n",
      "\n",
      "iteration 36_000  time: 4595.1 seconds\n",
      "\t \t loss(train :: test): 1.0452 :: 1.1495\n",
      "\t \t accuracy (train :: test): 67.4% :: 63.6%\n",
      "\t \t accuracy (last character) (train :: test): 71.1% :: 68.1%\n",
      "\n",
      "iteration 38_000  time: 4797.7 seconds\n",
      "\t \t loss(train :: test): 1.0424 :: 1.1673\n",
      "\t \t accuracy (train :: test): 66.9% :: 63.4%\n",
      "\t \t accuracy (last character) (train :: test): 76.2% :: 70.0%\n",
      "\n",
      "iteration 40_000  time: 4998.7 seconds\n",
      "\t \t loss(train :: test): 1.0596 :: 1.1414\n",
      "\t \t accuracy (train :: test): 66.4% :: 64.2%\n",
      "\t \t accuracy (last character) (train :: test): 64.8% :: 70.2%\n",
      "\n",
      "iteration 42_000  time: 5198.7 seconds\n",
      "\t \t loss(train :: test): 1.0243 :: 1.1570\n",
      "\t \t accuracy (train :: test): 67.7% :: 63.7%\n",
      "\t \t accuracy (last character) (train :: test): 70.3% :: 69.1%\n",
      "\n",
      "iteration 44_000  time: 5400.3 seconds\n",
      "\t \t loss(train :: test): 1.0572 :: 1.1277\n",
      "\t \t accuracy (train :: test): 66.4% :: 64.5%\n",
      "\t \t accuracy (last character) (train :: test): 68.0% :: 67.9%\n",
      "\n",
      "iteration 46_000  time: 5601.1 seconds\n",
      "\t \t loss(train :: test): 1.0338 :: 1.1626\n",
      "\t \t accuracy (train :: test): 67.4% :: 63.6%\n",
      "\t \t accuracy (last character) (train :: test): 72.3% :: 71.3%\n",
      "\n",
      "iteration 48_000  time: 5800.0 seconds\n",
      "\t \t loss(train :: test): 1.0611 :: 1.1248\n",
      "\t \t accuracy (train :: test): 66.6% :: 64.5%\n",
      "\t \t accuracy (last character) (train :: test): 67.6% :: 71.5%\n",
      "\n",
      "iteration 50_000  time: 5999.4 seconds\n",
      "\t \t loss(train :: test): 1.0569 :: 1.1332\n",
      "\t \t accuracy (train :: test): 66.9% :: 64.3%\n",
      "\t \t accuracy (last character) (train :: test): 66.8% :: 69.4%\n",
      "\n",
      "iteration 52_000  time: 6200.6 seconds\n",
      "\t \t loss(train :: test): 1.0545 :: 1.1373\n",
      "\t \t accuracy (train :: test): 66.6% :: 64.5%\n",
      "\t \t accuracy (last character) (train :: test): 69.9% :: 68.7%\n",
      "\n",
      "iteration 54_000  time: 6631.8 seconds\n",
      "\t \t loss(train :: test): 1.0222 :: 1.1667\n",
      "\t \t accuracy (train :: test): 67.9% :: 63.3%\n",
      "\t \t accuracy (last character) (train :: test): 71.9% :: 68.4%\n",
      "\n",
      "iteration 56_000  time: 7038.8 seconds\n",
      "\t \t loss(train :: test): 1.0181 :: 1.1257\n",
      "\t \t accuracy (train :: test): 67.1% :: 64.7%\n",
      "\t \t accuracy (last character) (train :: test): 68.4% :: 71.9%\n",
      "\n",
      "iteration 58_000  time: 7440.1 seconds\n",
      "\t \t loss(train :: test): 1.0187 :: 1.1312\n",
      "\t \t accuracy (train :: test): 67.5% :: 64.4%\n",
      "\t \t accuracy (last character) (train :: test): 65.6% :: 70.5%\n",
      "\n",
      "iteration 60_000  time: 7836.7 seconds\n",
      "\t \t loss(train :: test): 1.0091 :: 1.1323\n",
      "\t \t accuracy (train :: test): 68.2% :: 64.5%\n",
      "\t \t accuracy (last character) (train :: test): 76.6% :: 71.4%\n",
      "\n",
      "iteration 62_000  time: 8169.7 seconds\n",
      "\t \t loss(train :: test): 1.0194 :: 1.1134\n",
      "\t \t accuracy (train :: test): 67.8% :: 65.0%\n",
      "\t \t accuracy (last character) (train :: test): 64.5% :: 71.4%\n",
      "\n",
      "iteration 64_000  time: 8371.6 seconds\n",
      "\t \t loss(train :: test): 1.0287 :: 1.1310\n",
      "\t \t accuracy (train :: test): 67.4% :: 64.3%\n",
      "\t \t accuracy (last character) (train :: test): 68.8% :: 66.5%\n",
      "\n",
      "iteration 66_000  time: 8572.6 seconds\n",
      "\t \t loss(train :: test): 1.0487 :: 1.1246\n",
      "\t \t accuracy (train :: test): 67.0% :: 64.6%\n",
      "\t \t accuracy (last character) (train :: test): 67.6% :: 69.8%\n",
      "\n",
      "iteration 68_000  time: 8771.3 seconds\n",
      "\t \t loss(train :: test): 1.0111 :: 1.1332\n",
      "\t \t accuracy (train :: test): 67.6% :: 64.5%\n",
      "\t \t accuracy (last character) (train :: test): 75.8% :: 68.9%\n",
      "\n",
      "iteration 70_000  time: 8970.3 seconds\n",
      "\t \t loss(train :: test): 1.0230 :: 1.1271\n",
      "\t \t accuracy (train :: test): 67.6% :: 64.4%\n",
      "\t \t accuracy (last character) (train :: test): 73.8% :: 69.2%\n",
      "\n",
      "iteration 72_000  time: 9173.1 seconds\n",
      "\t \t loss(train :: test): 0.9913 :: 1.1393\n",
      "\t \t accuracy (train :: test): 68.6% :: 64.2%\n",
      "\t \t accuracy (last character) (train :: test): 68.0% :: 69.1%\n",
      "\n",
      "iteration 74_000  time: 9373.6 seconds\n",
      "\t \t loss(train :: test): 1.0004 :: 1.1414\n",
      "\t \t accuracy (train :: test): 68.2% :: 64.4%\n",
      "\t \t accuracy (last character) (train :: test): 75.0% :: 70.4%\n",
      "\n",
      "iteration 76_000  time: 9574.8 seconds\n",
      "\t \t loss(train :: test): 0.9689 :: 1.1169\n",
      "\t \t accuracy (train :: test): 69.5% :: 64.7%\n",
      "\t \t accuracy (last character) (train :: test): 73.8% :: 69.7%\n",
      "\n",
      "iteration 78_000  time: 9779.8 seconds\n",
      "\t \t loss(train :: test): 0.9987 :: 1.1213\n",
      "\t \t accuracy (train :: test): 68.1% :: 64.9%\n",
      "\t \t accuracy (last character) (train :: test): 76.2% :: 69.6%\n",
      "\n",
      "iteration 80_000  time: 9980.8 seconds\n",
      "\t \t loss(train :: test): 1.0154 :: 1.1419\n",
      "\t \t accuracy (train :: test): 67.7% :: 64.3%\n",
      "\t \t accuracy (last character) (train :: test): 74.2% :: 67.8%\n",
      "\n",
      "iteration 82_000  time: 10183.3 seconds\n",
      "\t \t loss(train :: test): 1.0240 :: 1.1229\n",
      "\t \t accuracy (train :: test): 67.8% :: 64.7%\n",
      "\t \t accuracy (last character) (train :: test): 75.0% :: 72.9%\n",
      "\n",
      "iteration 84_000  time: 10383.3 seconds\n",
      "\t \t loss(train :: test): 0.9971 :: 1.1373\n",
      "\t \t accuracy (train :: test): 68.8% :: 64.6%\n",
      "\t \t accuracy (last character) (train :: test): 71.9% :: 69.2%\n",
      "\n",
      "iteration 86_000  time: 10584.5 seconds\n",
      "\t \t loss(train :: test): 0.9768 :: 1.1240\n",
      "\t \t accuracy (train :: test): 69.2% :: 65.0%\n",
      "\t \t accuracy (last character) (train :: test): 71.9% :: 71.9%\n",
      "\n",
      "iteration 88_000  time: 10785.7 seconds\n",
      "\t \t loss(train :: test): 0.9994 :: 1.1292\n",
      "\t \t accuracy (train :: test): 68.4% :: 64.7%\n",
      "\t \t accuracy (last character) (train :: test): 69.5% :: 68.5%\n",
      "\n",
      "iteration 90_000  time: 10985.5 seconds\n",
      "\t \t loss(train :: test): 0.9998 :: 1.1140\n",
      "\t \t accuracy (train :: test): 68.3% :: 65.1%\n",
      "\t \t accuracy (last character) (train :: test): 71.1% :: 70.3%\n",
      "\n",
      "iteration 92_000  time: 11184.9 seconds\n",
      "\t \t loss(train :: test): 0.9760 :: 1.1263\n",
      "\t \t accuracy (train :: test): 69.2% :: 64.9%\n",
      "\t \t accuracy (last character) (train :: test): 68.8% :: 69.4%\n",
      "\n",
      "iteration 94_000  time: 11387.2 seconds\n",
      "\t \t loss(train :: test): 0.9828 :: 1.1221\n",
      "\t \t accuracy (train :: test): 69.3% :: 64.8%\n",
      "\t \t accuracy (last character) (train :: test): 73.0% :: 69.6%\n",
      "\n",
      "iteration 96_000  time: 11586.5 seconds\n",
      "\t \t loss(train :: test): 1.0178 :: 1.1436\n",
      "\t \t accuracy (train :: test): 67.8% :: 64.4%\n",
      "\t \t accuracy (last character) (train :: test): 73.0% :: 69.6%\n",
      "\n",
      "iteration 98_000  time: 11787.1 seconds\n",
      "\t \t loss(train :: test): 0.9908 :: 1.1224\n",
      "\t \t accuracy (train :: test): 68.6% :: 64.8%\n",
      "\t \t accuracy (last character) (train :: test): 69.1% :: 73.1%\n",
      "\n",
      "iteration 100_000  time: 12053.3 seconds\n",
      "\t \t loss(train :: test): 1.0010 :: 1.1222\n",
      "\t \t accuracy (train :: test): 68.5% :: 64.7%\n",
      "\t \t accuracy (last character) (train :: test): 64.8% :: 68.9%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "niter = 100_000\n",
    "B, T = 64, 256\n",
    "loss_history = []\n",
    "time_history = []\n",
    "time_test_history = []\n",
    "loss_test_history = []\n",
    "time_start = time.time()\n",
    "for it in range(1, niter + 1):\n",
    "    batch = get_batch(train_text_int, B, T)\n",
    "    input, target = batch[0], batch[1]\n",
    "    params_new, opt_state_new, metrics = train_step(params, opt_state, input, target, tx)\n",
    "\n",
    "    # update params and opt_state\n",
    "    params = params_new\n",
    "    opt_state = opt_state_new\n",
    "    acc = metrics['acc']\n",
    "    acc_last = metrics['acc_last']\n",
    "    loss = metrics['loss']\n",
    "\n",
    "    loss_history.append(loss)\n",
    "    time_history.append(time.time() - time_start)\n",
    "    run.log({\n",
    "        \"loss/train\": loss, \n",
    "        \"train_accuracy\": acc, \n",
    "        \"train_last_character_accuracy\": acc_last,\n",
    "    })\n",
    "\n",
    "    if it % (niter // 50) == 0 or it == 1:\n",
    "        time_since_start = time.time() - time_start\n",
    "        # compute loss on test set\n",
    "        B_test, T_test = 1024, 32\n",
    "        test_batch = get_batch(test_text_int, B_test, T_test)\n",
    "        test_input, test_target = test_batch[0], test_batch[1]\n",
    "        test_logits = model.apply({\"params\": params}, test_input)\n",
    "        test_loss, test_metrics = loss_and_metrics(test_logits, test_target)\n",
    "        test_acc = test_metrics['acc']\n",
    "        test_acc_last = test_metrics['acc_last']\n",
    "        loss_test_history.append(test_loss)\n",
    "        time_test_history.append(time_since_start)\n",
    "        run.log({\n",
    "            \"loss/test\": test_loss, \n",
    "            \"test_accuracy\": test_acc, \n",
    "            \"test_last_character_accuracy\": test_acc_last,\n",
    "        })\n",
    "        print(f\"iteration {it:_}  time: {time_since_start:.1f} seconds\")\n",
    "        print(f\"\\t \\t loss(train :: test): {loss:.4f} :: {test_loss:.4f}\")\n",
    "        print(f\"\\t \\t accuracy (train :: test): {100*acc:.1f}% :: {100*test_acc:.1f}%\")\n",
    "        print(f\"\\t \\t accuracy (last character) (train :: test): {100*acc_last:.1f}% :: {100*test_acc_last:.1f}%\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51dfc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_history, loss_history, '-', label='train', color=\"blue\")\n",
    "plt.plot(time_test_history, loss_test_history, '-', label='test', lw=2, color=\"red\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6e6f5",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13e56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_categorical(rng, logits, temperature=1.0):\n",
    "    \"\"\"Sample from categorical distribution given by logits with temperature.\"\"\"\n",
    "    # logits: (B, V)\n",
    "    if temperature != 1.0:\n",
    "        logits = logits / temperature\n",
    "    return jax.random.categorical(rng, logits, axis=-1)\n",
    "\n",
    "#@functools.partial(jax.jit, static_argnames=(\"model\", \"block_size\", \"temperature\", \"sample\"))\n",
    "def generate_tokens(model, params, rng, context, length, block_size=64, temperature=1.0, sample=True):\n",
    "    \"\"\"Generate `length` new tokens autoregressively starting from `context`.\n",
    "\n",
    "    Args:\n",
    "      model: Flax/linen model object with apply signature model.apply({'params': params}, tokens)\n",
    "      params: model parameters pytree.\n",
    "      rng: jax PRNGKey (e.g., jax.random.PRNGKey(0)).\n",
    "      context: int32 array shape (B, S) where S <= block_size. If S < block_size, left-pad with zeros or use full context.\n",
    "      length: number of tokens to generate (int).\n",
    "      block_size: model context window (static).\n",
    "      temperature: sampling temperature (static).\n",
    "      sample: if True use sampling; if False use argmax (greedy).\n",
    "\n",
    "    Returns:\n",
    "      generated: int32 array shape (B, length) of generated token ids.\n",
    "    \"\"\"\n",
    "    B = context.shape[0]\n",
    "    S = context.shape[1]\n",
    "    assert S <= block_size, \"context length must be <= block_size\"\n",
    "\n",
    "    # initialize running context: if S < block_size, left-pad with zeros (or use a preferred pad token)\n",
    "    if S < block_size:\n",
    "        pad_len = block_size - S\n",
    "        context = jnp.concatenate([jnp.zeros((B, pad_len), dtype=jnp.int32), context], axis=1)\n",
    "\n",
    "    def _step(carry, _):\n",
    "        rng, ctx = carry  # rng: PRNGKey, ctx: (B, block_size)\n",
    "        # forward pass: get logits for all positions, take last position\n",
    "        logits = model.apply({\"params\": params}, ctx)  # (B, block_size, V)\n",
    "        last_logits = logits[:, -1, :]  # (B, V)\n",
    "        rng, subkey = jax.random.split(rng)\n",
    "        if sample:\n",
    "            next_token = jax.random.categorical(subkey, last_logits / (temperature if temperature>0 else 1.0), axis=-1)\n",
    "        else:\n",
    "            next_token = jnp.argmax(last_logits, axis=-1)\n",
    "        next_token = next_token.astype(jnp.int32)\n",
    "        # append to context: drop first token, append new token at end\n",
    "        next_token_col = next_token.reshape(B, 1)\n",
    "        new_ctx = jnp.concatenate([ctx[:, 1:], next_token_col], axis=1)\n",
    "        return (rng, new_ctx), next_token_col\n",
    "\n",
    "    # run scan for `length` steps\n",
    "    (rng_final, ctx_final), tokens = jax.lax.scan(_step, (rng, context), None, length=length)\n",
    "    # tokens: shape (length, B, 1) -> reshape to (B, length)\n",
    "    tokens = tokens.squeeze(-1).transpose(1, 0)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e3bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated ids shape: (1, 1000)\n",
      "generated text:\n",
      "hello my friend and impressionist pianist olivier maria sharpe stockzire s born appearance in one nine two two and one nine three two as a result of the united states and other regional groups at the battle of the iranian provinces of kuwait province central and south america since one nine seven zero and one nine eight zero and international english language scene in english politics and politics in welsh he also appealed to the privilege of the golden dawn parenting in management in both the beast and self portrait the first book of the years grand rapids the book of priests in the first half of the twelve articles of confederation from the united kingdom to latin religion its failure to conquer a central part of the seventh century and the rest of the language for germans is that no one particularly well distinguished parties from the party on the more detailed discussion of large well beyond the court in a similar court act on the first university of st andrews s university of california berke\n"
     ]
    }
   ],
   "source": [
    "B = 1\n",
    "seed = 42\n",
    "rng = jax.random.PRNGKey(seed)\n",
    "prompt = \"hello my fri\"\n",
    "# prompt_int = encode(prompt.lower())\n",
    "prompt_int = jnp.array([ [char_to_int.get(c, len(char_set)) for c in prompt.lower()[:64]] ], dtype=jnp.int32)\n",
    "\n",
    "gen_len = 1000\n",
    "out_ids = generate_tokens(model, params, rng, prompt_int, gen_len, block_size=64, \n",
    "                          temperature=0.7, sample=True)\n",
    "print('generated ids shape:', out_ids.shape)\n",
    "print('generated text:')\n",
    "generated_text = ''.join(int_to_char.get(int(x), '?') for x in list(out_ids[0]))\n",
    "# concatenate with prompt\n",
    "print(prompt + generated_text)\n",
    "#print(''.join(int_to_char.get(int(x), '?') for x in list(out_ids[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e6d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 7,898,624\n"
     ]
    }
   ],
   "source": [
    "def count_params(params):\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "print(f\"Number of parameters: {count_params(params):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018b39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('decoder_transformer_RoPE_model_params-T3.pkl', 'wb') as f:\n",
    "    pickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eb20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
